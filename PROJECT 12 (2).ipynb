{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98173428",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\43664\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\43664\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\43664\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\43664\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'pad_sequences' from 'keras.preprocessing.sequence' (C:\\Users\\43664\\anaconda3\\lib\\site-packages\\keras\\preprocessing\\sequence.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2216/1997059310.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msequence\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEmbedding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'pad_sequences' from 'keras.preprocessing.sequence' (C:\\Users\\43664\\anaconda3\\lib\\site-packages\\keras\\preprocessing\\sequence.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import nltk  \n",
    "import re \n",
    "from string import punctuation\n",
    "from nltk.tokenize import WordPunctTokenizer, PunktSentenceTokenizer\n",
    "from nltk.corpus import wordnet, stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt')\n",
    "\n",
    "import string\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Embedding, LSTM, Dense\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a769ff36",
   "metadata": {},
   "source": [
    "## Read and inspect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf666e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 404290 entries, 0 to 404289\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   id            404290 non-null  int64 \n",
      " 1   qid1          404290 non-null  int64 \n",
      " 2   qid2          404290 non-null  int64 \n",
      " 3   question1     404289 non-null  object\n",
      " 4   question2     404288 non-null  object\n",
      " 5   is_duplicate  404290 non-null  int64 \n",
      "dtypes: int64(4), object(2)\n",
      "memory usage: 18.5+ MB\n"
     ]
    }
   ],
   "source": [
    "raw_train_data = pd.read_csv('train.csv')\n",
    "raw_train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "fccae355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a5d8fec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id               int64\n",
       "qid1             int64\n",
       "qid2             int64\n",
       "question1       object\n",
       "question2       object\n",
       "is_duplicate     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9192b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\43664\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3444: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>How does the Surface Pro himself 4 compare wit...</td>\n",
       "      <td>Why did Microsoft choose core m3 and not core ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Should I have a hair transplant at age 24? How...</td>\n",
       "      <td>How much cost does hair transplant require?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>What but is the best way to send money from Ch...</td>\n",
       "      <td>What you send money to China?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Which food not emulsifiers?</td>\n",
       "      <td>What foods fibre?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>How \"aberystwyth\" start reading?</td>\n",
       "      <td>How their can I start reading?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  test_id                                          question1  \\\n",
       "0       0  How does the Surface Pro himself 4 compare wit...   \n",
       "1       1  Should I have a hair transplant at age 24? How...   \n",
       "2       2  What but is the best way to send money from Ch...   \n",
       "3       3                        Which food not emulsifiers?   \n",
       "4       4                   How \"aberystwyth\" start reading?   \n",
       "\n",
       "                                           question2  \n",
       "0  Why did Microsoft choose core m3 and not core ...  \n",
       "1        How much cost does hair transplant require?  \n",
       "2                      What you send money to China?  \n",
       "3                                  What foods fibre?  \n",
       "4                     How their can I start reading?  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_test_data = pd.read_csv('test.csv')\n",
    "raw_test_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c3fecc41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id              0\n",
      "qid1            0\n",
      "qid2            0\n",
      "question1       1\n",
      "question2       2\n",
      "is_duplicate    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(raw_train_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c2c094d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "test_id      0\n",
       "question1    4\n",
       "question2    6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_test_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08d3586",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5745c2c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = raw_train_data.dropna(axis=0)\n",
    "test_data = raw_train_data.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "bcb03ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id              0\n",
       "qid1            0\n",
       "qid2            0\n",
       "question1       0\n",
       "question2       0\n",
       "is_duplicate    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9465ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id              0\n",
       "qid1            0\n",
       "qid2            0\n",
       "question1       0\n",
       "question2       0\n",
       "is_duplicate    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0aef1ed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           question1  \\\n",
       "0  What is the step by step guide to invest in sh...   \n",
       "1  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2  How can I increase the speed of my internet co...   \n",
       "3  Why am I mentally very lonely? How can I solve...   \n",
       "4  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = train_data.drop(['id', 'qid1', 'qid2'], axis=1)\n",
    "train_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "93b2e97e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the step by step guide to invest in share market in india?'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['question1'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "e7b9f3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_copy = train_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9b8643",
   "metadata": {},
   "source": [
    "## Text Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "ed42e01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## REMOVE ACCENTED CHARACTERS Sómě Áccěntěd těxt ##\n",
    "import unicodedata\n",
    "\n",
    "def remove_accented_chars_func(text):\n",
    "    return unicodedata.normalize('NFKD', str(text)).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "\n",
    "## REMOVE PUNCTUATION ##\n",
    "\n",
    "def remove_punctuation_func(text):\n",
    "    return re.sub(r'[^a-zA-Z0-9]', ' ', str(text))\n",
    "\n",
    "## REMOVE IRRELEVANT CHARACTERS \n",
    "\n",
    "def remove_irr_char_func(text):\n",
    "    return re.sub(r'[^a-zA-Z]', ' ', str(text))\n",
    "\n",
    "## REMOVE EXTRA WHITESPACEs ##\n",
    "\n",
    "def remove_extra_whitespaces_func(text):\n",
    "    return re.sub(r'^\\s*|\\s\\s*', ' ', str(text)).strip()\n",
    "\n",
    "## COUNT OF STRINGS ##\n",
    "\n",
    "def word_count_func(text):\n",
    "    return len(str(text).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "695543c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what is the story of kohinoor koh i noor diamond</td>\n",
       "      <td>what would happen if the indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how can i increase the speed of my internet co...</td>\n",
       "      <td>how can internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>why am i mentally very lonely how can i solve it</td>\n",
       "      <td>find the remainder when math math is divided by</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>which one dissolve in water quikly sugar salt ...</td>\n",
       "      <td>which fish would survive in salt water</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           question1  \\\n",
       "0  what is the step by step guide to invest in sh...   \n",
       "1   what is the story of kohinoor koh i noor diamond   \n",
       "2  how can i increase the speed of my internet co...   \n",
       "3   why am i mentally very lonely how can i solve it   \n",
       "4  which one dissolve in water quikly sugar salt ...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  what is the step by step guide to invest in sh...             0  \n",
       "1  what would happen if the indian government sto...             0  \n",
       "2  how can internet speed be increased by hacking...             0  \n",
       "3    find the remainder when math math is divided by             0  \n",
       "4             which fish would survive in salt water             0  "
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_copy['question1'] = train_copy['question1'].str.lower()\n",
    "train_copy['question2'] = train_copy['question2'].str.lower()\n",
    "\n",
    "train_copy['question1'] = train_copy['question1'].apply(remove_accented_chars_func)\n",
    "train_copy['question2'] = train_copy['question2'].apply(remove_accented_chars_func)\n",
    "\n",
    "train_copy['question1'] = train_copy['question1'].apply(remove_punctuation_func)\n",
    "train_copy['question2'] = train_copy['question2'].apply(remove_punctuation_func)\n",
    "\n",
    "train_copy['question1'] = train_copy['question1'].apply(remove_irr_char_func)\n",
    "train_copy['question2'] = train_copy['question2'].apply(remove_irr_char_func)\n",
    "\n",
    "train_copy['question1'] = train_copy['question1'].apply(remove_extra_whitespaces_func)\n",
    "train_copy['question2'] = train_copy['question2'].apply(remove_extra_whitespaces_func)\n",
    "\n",
    "train_copy.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec85816a",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "5e209d87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what is the story of kohinoor koh i noor diamond</td>\n",
       "      <td>what would happen if the indian government sto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how can i increase the speed of my internet co...</td>\n",
       "      <td>how can internet speed be increased by hacking...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>why am i mentally very lonely how can i solve it</td>\n",
       "      <td>find the remainder when math math is divided by</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>which one dissolve in water quikly sugar salt ...</td>\n",
       "      <td>which fish would survive in salt water</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           question1  \\\n",
       "0  what is the step by step guide to invest in sh...   \n",
       "1   what is the story of kohinoor koh i noor diamond   \n",
       "2  how can i increase the speed of my internet co...   \n",
       "3   why am i mentally very lonely how can i solve it   \n",
       "4  which one dissolve in water quikly sugar salt ...   \n",
       "\n",
       "                                           question2  \n",
       "0  what is the step by step guide to invest in sh...  \n",
       "1  what would happen if the indian government sto...  \n",
       "2  how can internet speed be increased by hacking...  \n",
       "3    find the remainder when math math is divided by  \n",
       "4             which fish would survive in salt water  "
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = ['question1', 'question2']\n",
    "\n",
    "X_data = train_copy[features]\n",
    "X_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "e9472ca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: is_duplicate, dtype: int64"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data = train_copy['is_duplicate']\n",
    "y_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "f29440ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whole dataset:  404287\n",
      "X_train size = 40428\n",
      "X_split size = 363859\n",
      "y_train size = 40428\n",
      "y_split size = 363859\n"
     ]
    }
   ],
   "source": [
    "# Split the set into train and split data into 60/40, random_state 0\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_split, y_train, y_split = train_test_split(X_data, y_data, test_size=0.90, random_state = 0)  ## cambiar test size\n",
    "\n",
    "print(\"Whole dataset: \", len(train_copy))\n",
    "print(\"X_train size =\", len(X_train))\n",
    "print(\"X_split size =\", len(X_split))\n",
    "print(\"y_train size =\", len(y_train))\n",
    "print(\"y_split size =\", len(y_split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "7db3871b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whole dataset:  404287\n",
      "X_test size = 80857\n",
      "X_val size = 80858\n",
      "y_test size = 80857\n",
      "y_val size = 80858\n"
     ]
    }
   ],
   "source": [
    "# Split the set into test and validation into 50/50 (from 40% of the splitted data), random_state 0\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_split, y_split, test_size=0.50, random_state = 0)\n",
    "\n",
    "print(\"Whole dataset: \", len(train_copy))\n",
    "print(\"X_test size =\", len(X_test))\n",
    "print(\"X_val size =\", len(X_val))\n",
    "print(\"y_test size =\", len(y_test))\n",
    "print(\"y_val size =\", len(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "192a5593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>189347</th>\n",
       "      <td>what are the most asked mainframe interview qu...</td>\n",
       "      <td>what is the most asked question in an interview</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327140</th>\n",
       "      <td>how long should i wait for my bitcoin core wal...</td>\n",
       "      <td>can one set up a bitcoin wallet under false id...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126940</th>\n",
       "      <td>i got selected for internship at inria th june...</td>\n",
       "      <td>i got selected for internship at inria th june...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78406</th>\n",
       "      <td>how do you stay fit if you don t like the gym</td>\n",
       "      <td>how can i stay fit with out going gym</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372855</th>\n",
       "      <td>what is the best budget hotels in cochin for a...</td>\n",
       "      <td>what is the best budget hotels in mussoorie fo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                question1  \\\n",
       "189347  what are the most asked mainframe interview qu...   \n",
       "327140  how long should i wait for my bitcoin core wal...   \n",
       "126940  i got selected for internship at inria th june...   \n",
       "78406       how do you stay fit if you don t like the gym   \n",
       "372855  what is the best budget hotels in cochin for a...   \n",
       "\n",
       "                                                question2  \n",
       "189347    what is the most asked question in an interview  \n",
       "327140  can one set up a bitcoin wallet under false id...  \n",
       "126940  i got selected for internship at inria th june...  \n",
       "78406               how can i stay fit with out going gym  \n",
       "372855  what is the best budget hotels in mussoorie fo...  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6c947d",
   "metadata": {},
   "source": [
    "## Text Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c930da31",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "a98d56e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### X_train ###\n",
    "## QUESTION 1 ##\n",
    "X_train_text_q1 = X_train['question1'] \n",
    "\n",
    "X_train_q1 = []\n",
    "\n",
    "for sent_train_q1 in X_train_text_q1:\n",
    "    \n",
    "    #lowercase\n",
    "    #sent = sent.lower()\n",
    "  \n",
    "    sent_train_q1 = sent_train_q1.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "  ## tokenize ##\n",
    "    train_tokens_q1 = nltk.word_tokenize(sent_train_q1)\n",
    "\n",
    "  ## remove stop-words ##\n",
    "    english_stopwords = stopwords.words('english')\n",
    "    #english_stopwords = english_stopwords + ['did', 'could', 'would', 'have', 'had', 'has', 'might', 'should', 'was', 'were', 'does', 'much', 'br', 'n']\n",
    "    train_tokens_q1 = [el for el in train_tokens_q1 if not el in english_stopwords]\n",
    "\n",
    "  ## lemmatization ##\n",
    " \n",
    "    #train_tokens_lemma_q1 = [wnl.lemmatize(el, get_wordnet_pos(nltk.pos_tag([el])[0][1])) for el in train_tokens_q1]\n",
    "\n",
    "  ## add to output list ##\n",
    "    X_train_q1.append(\" \".join(train_tokens_q1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "e8fce6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### X_train ###\n",
    "## QUESTION 2 ##\n",
    "X_train_text_q2 = X_train['question2'] \n",
    "\n",
    "X_train_q2 = []\n",
    "\n",
    "for sent_train_q2 in X_train_text_q2:\n",
    "    \n",
    "    #lowercase\n",
    "    #sent = sent.lower()\n",
    "  \n",
    "    sent_train_q2 = sent_train_q2.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "  ## tokenize ##\n",
    "    train_tokens_q2 = nltk.word_tokenize(sent_train_q2)\n",
    "\n",
    "  ## remove stop-words ##\n",
    "    english_stopwords = stopwords.words('english')\n",
    "    #english_stopwords = english_stopwords + ['did', 'could', 'would', 'have', 'had', 'has', 'might', 'should', 'was', 'were', 'does', 'much', 'br', 'n']\n",
    "    train_tokens_q2 = [el for el in train_tokens_q2 if not el in english_stopwords]\n",
    "\n",
    "  ## lemmatization ##\n",
    " \n",
    "    #train_tokens_lemma_q2 = [wnl.lemmatize(el, get_wordnet_pos(nltk.pos_tag([el])[0][1])) for el in train_tokens_q1]\n",
    "\n",
    "  ## add to output list ##\n",
    "    X_train_q2.append(\" \".join(train_tokens_q2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "b219b59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### X_test ###\n",
    "## QUESTION 1 ##\n",
    "X_test_text_q1 = X_test['question1'] \n",
    "\n",
    "X_test_q1 = []\n",
    "\n",
    "for sent_test_q1 in X_test_text_q1:\n",
    "    \n",
    "    #lowercase\n",
    "    #sent = sent.lower()\n",
    "  \n",
    "    sent_test_q1 = sent_test_q1.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "  ## tokenize ##\n",
    "    test_tokens_q1 = nltk.word_tokenize(sent_test_q1)\n",
    "\n",
    "  ## remove stop-words ##\n",
    "    english_stopwords = stopwords.words('english')\n",
    "    #english_stopwords = english_stopwords + ['did', 'could', 'would', 'have', 'had', 'has', 'might', 'should', 'was', 'were', 'does', 'much', 'br', 'n']\n",
    "    test_tokens_q1 = [el for el in test_tokens_q1 if not el in english_stopwords]\n",
    "\n",
    "  ## lemmatization ##\n",
    " \n",
    "    #test_tokens_lemma_q1 = [wnl.lemmatize(el, get_wordnet_pos(nltk.pos_tag([el])[0][1])) for el in test_tokens_q1]\n",
    "\n",
    "  ## add to output list ##\n",
    "    X_test_q1.append(\" \".join(test_tokens_q1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "e49b1549",
   "metadata": {},
   "outputs": [],
   "source": [
    "### X_test ###\n",
    "## QUESTION 1 ##\n",
    "X_test_text_q2 = X_test['question2'] \n",
    "\n",
    "X_test_q2 = []\n",
    "\n",
    "for sent_test_q2 in X_test_text_q2:\n",
    "    \n",
    "    #lowercase\n",
    "    #sent = sent.lower()\n",
    "  \n",
    "    sent_test_q2 = sent_test_q2.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "  ## tokenize ##\n",
    "    test_tokens_q2 = nltk.word_tokenize(sent_test_q2)\n",
    "\n",
    "  ## remove stop-words ##\n",
    "    english_stopwords = stopwords.words('english')\n",
    "    #english_stopwords = english_stopwords + ['did', 'could', 'would', 'have', 'had', 'has', 'might', 'should', 'was', 'were', 'does', 'much', 'br', 'n']\n",
    "    test_tokens_q2 = [el for el in test_tokens_q2 if not el in english_stopwords]\n",
    "\n",
    "  ## lemmatization ##\n",
    " \n",
    "    #test_tokens_lemma_q2 = [wnl.lemmatize(el, get_wordnet_pos(nltk.pos_tag([el])[0][1])) for el in test_tokens_q2]\n",
    "\n",
    "  ## add to output list ##\n",
    "    X_test_q2.append(\" \".join(test_tokens_q2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "d5479cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "### X_val ###\n",
    "## QUESTION 1 ##\n",
    "X_val_text_q1 = X_val['question1'] \n",
    "\n",
    "X_val_q1 = []\n",
    "\n",
    "for sent_val_q1 in X_val_text_q1:\n",
    "    \n",
    "    #lowercase\n",
    "    #sent = sent.lower()\n",
    "  \n",
    "    sent_val_q1 = sent_val_q1.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "  ## tokenize ##\n",
    "    val_tokens_q1 = nltk.word_tokenize(sent_val_q1)\n",
    "\n",
    "  ## remove stop-words ##\n",
    "    english_stopwords = stopwords.words('english')\n",
    "    #english_stopwords = english_stopwords + ['did', 'could', 'would', 'have', 'had', 'has', 'might', 'should', 'was', 'were', 'does', 'much', 'br', 'n']\n",
    "    val_tokens_q1 = [el for el in val_tokens_q1 if not el in english_stopwords]\n",
    "\n",
    "  ## lemmatization ##\n",
    " \n",
    "    #val_tokens_lemma_q1 = [wnl.lemmatize(el, get_wordnet_pos(nltk.pos_tag([el])[0][1])) for el in val_tokens_q1]\n",
    "\n",
    "  ## add to output list ##\n",
    "    X_val_q1.append(\" \".join(val_tokens_q1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "ad820fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### X_val ###\n",
    "## QUESTION 2 ##\n",
    "X_val_text_q2 = X_val['question2'] \n",
    "\n",
    "X_val_q2 = []\n",
    "\n",
    "for sent_val_q2 in X_val_text_q2:\n",
    "    \n",
    "    #lowercase\n",
    "    #sent = sent.lower()\n",
    "  \n",
    "    sent_val_q2 = sent_val_q2.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "  ## tokenize ##\n",
    "    val_tokens_q2 = nltk.word_tokenize(sent_val_q2)\n",
    "\n",
    "  ## remove stop-words ##\n",
    "    english_stopwords = stopwords.words('english')\n",
    "    #english_stopwords = english_stopwords + ['did', 'could', 'would', 'have', 'had', 'has', 'might', 'should', 'was', 'were', 'does', 'much', 'br', 'n']\n",
    "    val_tokens_q2 = [el for el in val_tokens_q2 if not el in english_stopwords]\n",
    "\n",
    "  ## lemmatization ##\n",
    " \n",
    "    #val_tokens_lemma_q2 = [wnl.lemmatize(el, get_wordnet_pos(nltk.pos_tag([el])[0][1])) for el in val_tokens_q2]\n",
    "\n",
    "  ## add to output list ##\n",
    "    X_val_q2.append(\" \".join(val_tokens_q2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98913adf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    What is the step by step guide to invest in sh...\n",
       "1    What is the story of Kohinoor (Koh-i-Noor) Dia...\n",
       "2    How can I increase the speed of my internet co...\n",
       "3    Why am I mentally very lonely? How can I solve...\n",
       "4    Which one dissolve in water quikly sugar, salt...\n",
       "5    Astrology: I am a Capricorn Sun Cap moon and c...\n",
       "6                                  Should I buy tiago?\n",
       "7                       How can I be a good geologist?\n",
       "8                      When do you use シ instead of し?\n",
       "9    Motorola (company): Can I hack my Charter Moto...\n",
       "Name: question1, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_copy['question1'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "c26b5fe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['asked question interview',\n",
       " 'one set bitcoin wallet false identity',\n",
       " 'got selected internship inria th june th sep eligible charpak research scholarship please specify long',\n",
       " 'stay fit going gym',\n",
       " 'best budget hotels mussoorie accommodation friends coming new year eve',\n",
       " 'property price decrease india money demonetisation',\n",
       " 'color mn',\n",
       " 'donald j trump presidency affect opportunities offered non us students',\n",
       " 'best coaching institute gate chandigarh',\n",
       " 'benjamin netanyahu display childish behaviors consistent basis']"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_q2[:10] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c9509375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           question1  \\\n",
      "0          step step guide invest share market india   \n",
      "1                    story kohinoor kohinoor diamond   \n",
      "2       increase speed internet connection using vpn   \n",
      "3                              mentally lonely solve   \n",
      "4  one dissolve water quikly sugar salt methane c...   \n",
      "\n",
      "                                           question2  \n",
      "0                step step guide invest share market  \n",
      "1  would happen indian government stole kohinoor ...  \n",
      "2               internet speed increased hacking dns  \n",
      "3           find remainder math2324math divided 2423  \n",
      "4                      fish would survive salt water  \n",
      "                                           question1\n",
      "0          step step guide invest share market india\n",
      "1                    story kohinoor kohinoor diamond\n",
      "2       increase speed internet connection using vpn\n",
      "3                              mentally lonely solve\n",
      "4  one dissolve water quikly sugar salt methane c...\n",
      "                                           question2\n",
      "0                step step guide invest share market\n",
      "1  would happen indian government stole kohinoor ...\n",
      "2               internet speed increased hacking dns\n",
      "3           find remainder math2324math divided 2423\n",
      "4                      fish would survive salt water\n"
     ]
    }
   ],
   "source": [
    "# df_q1 = pd.DataFrame(train_text_q1, columns=['question1'])\n",
    "# df_q2 = pd.DataFrame(train_text_q2, columns=['question2'])\n",
    "# #train_df = pd.concat([df_q1, df_q2], axis=0)\n",
    "# train_df = df_q1.join(df_q2, lsuffix='_left', rsuffix='_right')\n",
    "# print(train_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "c07900e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>best pick line person ever said</td>\n",
       "      <td>epic pick line ever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>meaning cc engine</td>\n",
       "      <td>cc engine indicate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>borivali churchgate kalyan cst journey better</td>\n",
       "      <td>someone think think soulmate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cool psychological hacks</td>\n",
       "      <td>reverse psychology life hacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>create empire st century</td>\n",
       "      <td>ever empire st century</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242567</th>\n",
       "      <td>java android</td>\n",
       "      <td>r java android</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242568</th>\n",
       "      <td>proper length men pants</td>\n",
       "      <td>proper length men suit pants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242569</th>\n",
       "      <td>know whether want mbbs something else</td>\n",
       "      <td>know really want become doctor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242570</th>\n",
       "      <td>hack snapchat chat history</td>\n",
       "      <td>spy snapchat chat history</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242571</th>\n",
       "      <td>social media changed world</td>\n",
       "      <td>social medial changed world</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>242572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question1  \\\n",
       "0                     best pick line person ever said   \n",
       "1                                   meaning cc engine   \n",
       "2       borivali churchgate kalyan cst journey better   \n",
       "3                            cool psychological hacks   \n",
       "4                            create empire st century   \n",
       "...                                               ...   \n",
       "242567                                   java android   \n",
       "242568                        proper length men pants   \n",
       "242569          know whether want mbbs something else   \n",
       "242570                     hack snapchat chat history   \n",
       "242571                     social media changed world   \n",
       "\n",
       "                             question2  \n",
       "0                  epic pick line ever  \n",
       "1                   cc engine indicate  \n",
       "2         someone think think soulmate  \n",
       "3        reverse psychology life hacks  \n",
       "4               ever empire st century  \n",
       "...                                ...  \n",
       "242567                  r java android  \n",
       "242568    proper length men suit pants  \n",
       "242569  know really want become doctor  \n",
       "242570       spy snapchat chat history  \n",
       "242571     social medial changed world  \n",
       "\n",
       "[242572 rows x 2 columns]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_q1 = pd.DataFrame(X_train_q1, columns=['question1'])\n",
    "df_q2 = pd.DataFrame(X_train_q2, columns=['question2'])\n",
    "# #train_df = pd.concat([df_q1, df_q2], axis=0)\n",
    "train_df = df_q1.join(df_q2, lsuffix='_left', rsuffix='_right')\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "c57eabbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>best pick line person ever said</td>\n",
       "      <td>epic pick line ever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>meaning cc engine</td>\n",
       "      <td>cc engine indicate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>borivali churchgate kalyan cst journey better</td>\n",
       "      <td>someone think think soulmate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cool psychological hacks</td>\n",
       "      <td>reverse psychology life hacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>create empire st century</td>\n",
       "      <td>ever empire st century</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242567</th>\n",
       "      <td>java android</td>\n",
       "      <td>r java android</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242568</th>\n",
       "      <td>proper length men pants</td>\n",
       "      <td>proper length men suit pants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242569</th>\n",
       "      <td>know whether want mbbs something else</td>\n",
       "      <td>know really want become doctor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242570</th>\n",
       "      <td>hack snapchat chat history</td>\n",
       "      <td>spy snapchat chat history</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242571</th>\n",
       "      <td>social media changed world</td>\n",
       "      <td>social medial changed world</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>242572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question1  \\\n",
       "0                     best pick line person ever said   \n",
       "1                                   meaning cc engine   \n",
       "2       borivali churchgate kalyan cst journey better   \n",
       "3                            cool psychological hacks   \n",
       "4                            create empire st century   \n",
       "...                                               ...   \n",
       "242567                                   java android   \n",
       "242568                        proper length men pants   \n",
       "242569          know whether want mbbs something else   \n",
       "242570                     hack snapchat chat history   \n",
       "242571                     social media changed world   \n",
       "\n",
       "                             question2  \n",
       "0                  epic pick line ever  \n",
       "1                   cc engine indicate  \n",
       "2         someone think think soulmate  \n",
       "3        reverse psychology life hacks  \n",
       "4               ever empire st century  \n",
       "...                                ...  \n",
       "242567                  r java android  \n",
       "242568    proper length men suit pants  \n",
       "242569  know really want become doctor  \n",
       "242570       spy snapchat chat history  \n",
       "242571     social medial changed world  \n",
       "\n",
       "[242572 rows x 2 columns]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12420896",
   "metadata": {},
   "source": [
    "# Using Spacy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "e266a26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_process(text):\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    #Tokenization and lemmatization are done with the spacy nlp pipeline commands\n",
    "    lemma_list = []\n",
    "    for token in doc:\n",
    "        lemma_list.append(token.lemma_)\n",
    "    print(\"Tokenize+Lemmatize:\")\n",
    "    print(lemma_list)\n",
    "    \n",
    "    #Filter the stopword\n",
    "    filtered_sentence =[] \n",
    "    for word in lemma_list:\n",
    "        lexeme = nlp.vocab[word]\n",
    "        if lexeme.is_stop == False:\n",
    "            filtered_sentence.append(word) \n",
    "    \n",
    "    #Remove punctuation\n",
    "    punctuations=\"?:!.,;\"\n",
    "    for word in filtered_sentence:\n",
    "        if word in punctuations:\n",
    "            filtered_sentence.remove(word)\n",
    "    print(\" \")\n",
    "    print(\"Remove stopword & punctuation: \")\n",
    "    print(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "388a7a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "08a9fcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "114685f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenize+Lemmatize:\n",
      "['15296', '    ', 'what', 'be', 'the', 'good', 'pick', 'up', 'line', 'a', 'person', 'have', 'eve', '...', '\\n', '223726', '                 ', 'what', 'be', 'the', 'meaning', 'of', 'cc', 'in', 'engine', '\\n', '276564', '   ', 'borivali', 'to', 'churchgate', 'or', 'kalyan', 'to', 'cst', 'which', '...', '\\n', '171976', '              ', 'what', 'be', 'some', 'cool', 'psychological', 'hack', '\\n', '107068', '       ', 'how', 'do', 'you', 'create', 'an', 'empire', 'in', 'the', 'st', 'century', '\\n                                ', '...', '                       \\n', '359785', '                           ', 'what', 'be', 'java', 'and', 'android', '\\n', '358085', '           ', 'what', 'be', 'the', 'proper', 'length', 'for', 'man', 's', 'pant', '\\n', '152316', '   ', 'how', 'do', 'I', 'know', 'whether', 'I', 'want', 'to', 'do', 'mbb', 'or', 'som', '...', '\\n', '117953', '            ', 'how', 'can', 'I', 'hack', 'the', 'snapchat', 'chat', 'history', '\\n', '305713', '              ', 'how', 'have', 'social', 'medium', 'change', 'the', 'world', '\\n', 'name', ':', 'question1', ',', 'length', ':', '242572', ',', 'dtype', ':', 'object']\n",
      " \n",
      "Remove stopword & punctuation: \n",
      "['15296', '    ', 'good', 'pick', 'line', 'person', 'eve', '...', '\\n', '223726', '                 ', 'meaning', 'cc', 'engine', '\\n', '276564', '   ', 'borivali', 'churchgate', 'kalyan', 'cst', '...', '\\n', '171976', '              ', 'cool', 'psychological', 'hack', '\\n', '107068', '       ', 'create', 'empire', 'st', 'century', '\\n                                ', '...', '                       \\n', '359785', '                           ', 'java', 'android', '\\n', '358085', '           ', 'proper', 'length', 'man', 's', 'pant', '\\n', '152316', '   ', 'know', 'want', 'mbb', 'som', '...', '\\n', '117953', '            ', 'hack', 'snapchat', 'chat', 'history', '\\n', '305713', '              ', 'social', 'medium', 'change', 'world', '\\n', 'question1', 'length', '242572', 'dtype', 'object']\n"
     ]
    }
   ],
   "source": [
    "#import spacy\n",
    "spacy_X_train_q1 = spacy_process(str(X_train['question1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "a43f5ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(spacy_X_train_q1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "e0ecf639",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize  \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "p_stemmer = PorterStemmer()\n",
    "#s_stemmer = SnowballStemmer(language='english')\n",
    "\n",
    "def nltk_process(text):\n",
    "    #Tokenization\n",
    "    nltk_tokenList = word_tokenize(text)\n",
    "    \n",
    "    #Stemming\n",
    "    nltk_stemedList = []\n",
    "    for word in nltk_tokenList:\n",
    "        nltk_stemedList.append(p_stemmer.stem(word))\n",
    "        #nltk_stemedList.append(s_stemmer.stem(word))\n",
    "    \n",
    "    #Lemmatization\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    nltk_lemmaList = []\n",
    "    for word in nltk_stemedList:\n",
    "        nltk_lemmaList.append(wordnet_lemmatizer.lemmatize(word))\n",
    "    \n",
    "    print(\"Stemming + Lemmatization\")\n",
    "    print(nltk_lemmaList)\n",
    "\n",
    "    #Filter stopword\n",
    "    filtered_sentence = []  \n",
    "    nltk_stop_words = set(stopwords.words(\"english\"))\n",
    "    for w in nltk_lemmaList:  \n",
    "        if w not in nltk_stop_words:  \n",
    "            filtered_sentence.append(w)  \n",
    "\n",
    "    #Removing Punctuation\n",
    "    punctuations=\"?:!.,;\"\n",
    "    for word in filtered_sentence:\n",
    "        if word in punctuations:\n",
    "            filtered_sentence.remove(word)\n",
    "    print(\" \")\n",
    "    print(\"Remove stopword & Punctuation\")\n",
    "    print(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "4b71d383",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2216/1604292560.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnltk_process\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_q2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2216/3429473322.py\u001b[0m in \u001b[0;36mnltk_process\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfiltered_sentence\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpunctuations\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m             \u001b[0mfiltered_sentence\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Remove stopword & Punctuation\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nltk_process(str(X_train_q2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e40532",
   "metadata": {},
   "source": [
    "## Labelling target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "6efd294c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 ... 1 1 1]\n",
      "[0 0 0 ... 0 0 1]\n",
      "[0 0 0 ... 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "labels = preprocessing.LabelEncoder()\n",
    "# Convert continous y values to categorical\n",
    "y_train_cat= labels.fit_transform(y_train)\n",
    "print(y_train_cat)\n",
    "\n",
    "y_val_cat = labels.fit_transform(y_val)\n",
    "print(y_val_cat)\n",
    "\n",
    "y_test_cat = labels.fit_transform(y_test)\n",
    "print(y_test_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d359e2",
   "metadata": {},
   "source": [
    "## Models \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3e8e6791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>187265</th>\n",
       "      <td>differences german austrian culture</td>\n",
       "      <td>cultural differences austria germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6557</th>\n",
       "      <td>best doctor doom stories</td>\n",
       "      <td>best comics featuring doctor doom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139264</th>\n",
       "      <td>best books prepare ssb</td>\n",
       "      <td>best books prepare iit jam physics exam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240135</th>\n",
       "      <td>ms vlsi portland state university good heard i...</td>\n",
       "      <td>universities apply ms vlsi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3336</th>\n",
       "      <td>height would 14 year old increase height</td>\n",
       "      <td>increase height</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33649</th>\n",
       "      <td>recommendation cheap hosting plan host 3 diffe...</td>\n",
       "      <td>host go daddy registered domain wordpress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120451</th>\n",
       "      <td>mean blood bright red</td>\n",
       "      <td>blood dark red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256699</th>\n",
       "      <td>trump want lose election possible evidence stu...</td>\n",
       "      <td>trump really want president selfdestructive stuff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64328</th>\n",
       "      <td>lewis structure c4h8 determined</td>\n",
       "      <td>lewis structure n2f4 determined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30272</th>\n",
       "      <td>waveparticle duality</td>\n",
       "      <td>wave waveparticle duality</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101072 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                question1  \\\n",
       "187265                differences german austrian culture   \n",
       "6557                             best doctor doom stories   \n",
       "139264                             best books prepare ssb   \n",
       "240135  ms vlsi portland state university good heard i...   \n",
       "3336             height would 14 year old increase height   \n",
       "...                                                   ...   \n",
       "33649   recommendation cheap hosting plan host 3 diffe...   \n",
       "120451                              mean blood bright red   \n",
       "256699  trump want lose election possible evidence stu...   \n",
       "64328                     lewis structure c4h8 determined   \n",
       "30272                                waveparticle duality   \n",
       "\n",
       "                                                question2  \n",
       "187265               cultural differences austria germany  \n",
       "6557                    best comics featuring doctor doom  \n",
       "139264            best books prepare iit jam physics exam  \n",
       "240135                         universities apply ms vlsi  \n",
       "3336                                      increase height  \n",
       "...                                                   ...  \n",
       "33649           host go daddy registered domain wordpress  \n",
       "120451                                     blood dark red  \n",
       "256699  trump really want president selfdestructive stuff  \n",
       "64328                     lewis structure n2f4 determined  \n",
       "30272                           wave waveparticle duality  \n",
       "\n",
       "[101072 rows x 2 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "5f532f7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best pick line person ever said',\n",
       " 'meaning cc engine',\n",
       " 'borivali churchgate kalyan cst journey better',\n",
       " 'cool psychological hacks',\n",
       " 'create empire st century',\n",
       " 'post question quora posted many rejected',\n",
       " 'partner get stop cuming quickly',\n",
       " 'best military instructional videos',\n",
       " 'wrong stephen colbert right ear',\n",
       " 'prisoners often think jail',\n",
       " 'prepare clat',\n",
       " 'fastest way charge iphone',\n",
       " 'overcome despair depression',\n",
       " 'best political leaders india',\n",
       " 'best golf wedge money',\n",
       " 'best book understand theory relativity',\n",
       " 'side effects protienx',\n",
       " 'best pomodoro app windows',\n",
       " 'solo traveler get laid',\n",
       " 'get complete list gmail accounts',\n",
       " 'valid reason dumped making partner wait sexual intimacy',\n",
       " 'characteristics ron harry hermione bring table',\n",
       " 'could happen lie bed one week smartphone food water',\n",
       " 'donald trump become racist',\n",
       " 'possible guy find guys attractive gay',\n",
       " 'effect braces hearing',\n",
       " 'long take see results intermittent fasting',\n",
       " 'difference procedural programming modular programming',\n",
       " 'em drive works top disc smaller bottom disc',\n",
       " 'many quorans obsessed iq',\n",
       " 'best free tools cross browser testing',\n",
       " 'book publisher india',\n",
       " 'small business ideas',\n",
       " 'medical insurance system turkey',\n",
       " 'getting credits answering even someone asks answer',\n",
       " 'line mean song starboy weeknd',\n",
       " 'one w bad credit get loan house buy another property',\n",
       " 'vladimir putin really threaten war hillary wins',\n",
       " 'dangers getting wisdom teeth pulled pregnant',\n",
       " 'activate whatsapp new iphone old number without insert sim',\n",
       " 'space music',\n",
       " 'equal',\n",
       " 'sun big',\n",
       " 'detox marijuana',\n",
       " 'much money hotel owners make per annum',\n",
       " 'biggest strengths indian army',\n",
       " 'technical resignation',\n",
       " 'water cement ratio associated strength concrete',\n",
       " 'cs tougher cfa way round',\n",
       " 'needs market research report',\n",
       " 'hell high water movie',\n",
       " 'best mba colleges gwalior',\n",
       " 'path learning java web development technologies',\n",
       " 'modern examples government corruption egypt',\n",
       " 'highest degree tae kwon',\n",
       " 'programming languages best learn',\n",
       " 'someone explain spring airsoft sniper rifle accuracy international replica l skewing curving right shoot long range',\n",
       " 'would guy ask girl write poem',\n",
       " 'process edit nikon raw nef files gimp',\n",
       " 'could one account pinterest email',\n",
       " 'india ban import chinese goods answer stance nsg',\n",
       " 'much paying create top quality online clothing store sell products india',\n",
       " 'much money uber drivers make',\n",
       " 'views governments decision stop flow rupee notes',\n",
       " 'conservative bourgeois socialist still considered true socialist',\n",
       " 'cause pimples inside cheekbones',\n",
       " 'know psychopath',\n",
       " 'difference inertia static friction',\n",
       " 'get best assistance sydney lighting repairs installation design',\n",
       " 'best songs bon jovi songs played guitar',\n",
       " 'haunted places bangladesh',\n",
       " 'best way get date',\n",
       " 'improve social life college',\n",
       " 'anyone successfully escape alcatraz prison',\n",
       " 'z security',\n",
       " 'could go back time would tell year old self',\n",
       " 'governments obliged law respond citizens requests',\n",
       " 'really bad living compton ghettos movies rappers people around would us believe',\n",
       " 'symptoms parkinson disease',\n",
       " 'hydrolysis atp provide energy',\n",
       " 'killed mahatma gandhi',\n",
       " 'corruption government sector private sector india',\n",
       " 'incest sister wants see penis taking health never seen one show',\n",
       " 'left mirror nano broken root',\n",
       " 'balaji vishwanathan make youtube videos spread knowledge people learn',\n",
       " 'interview questions asked quality assurance engineer amazon',\n",
       " 'dogs know difference hand petting foot petting',\n",
       " 'boy feel put penis inside vagina',\n",
       " 'big bang occur',\n",
       " 'examples abstract concrete nouns',\n",
       " 'fastest way build muscle',\n",
       " 'madison square garden replaced',\n",
       " 'great lord rings',\n",
       " 'supreme court invalidate th constitutional amendment collegium system appointing supreme court judges',\n",
       " 'best aipmt coaching centre dehradun',\n",
       " 'many people ask questions quora found google search',\n",
       " 'undefined',\n",
       " 'doc vec create vector document',\n",
       " 'cat sleep like human',\n",
       " 'get cold twice',\n",
       " 'want make video games start need know',\n",
       " 'want buy tag huer grand carrera mercedes benz sls edition watch find india',\n",
       " 'difference simple cell capacitors',\n",
       " 'fresher company better accenture cognizant infosys',\n",
       " 'meaning name manishaa',\n",
       " 'web series rwby considered anime',\n",
       " 'remove primary sole network facebook',\n",
       " 'solicitor barrister differ',\n",
       " 'difference row tuple dbms',\n",
       " 'ways glue styrofoam together',\n",
       " 'much file patent',\n",
       " 'lose pounds days',\n",
       " 'entrepreneurs',\n",
       " 'real estate market tamil nadu next boom',\n",
       " 'percentage athletes rio summer olympics representing country born lived lives',\n",
       " 'part time jobs australia',\n",
       " 'find latest z materials',\n",
       " 'increase english fluency',\n",
       " 'hours live',\n",
       " 'function ribosomes serve',\n",
       " 'men realize made mistake letting go truly love',\n",
       " 'share video facebook whatsapp',\n",
       " 'miss memories person',\n",
       " 'send whatsapp message bulk free',\n",
       " 'life stanford',\n",
       " 'improve learning skills',\n",
       " 'find better alone able develop good friend still jealousy see people enjoying normal',\n",
       " 'must wedding rings worn left hand',\n",
       " 'cop viewed pull another cop',\n",
       " 'apple buy google',\n",
       " 'advantage transmission system motorcycles india neutral gear st nd gear instead one neutral st',\n",
       " 'top blogs online media sites catering entrepreneurs germany',\n",
       " 'best books ssc cgl preparation',\n",
       " 'get someone dread hair without spending entire life savings live md u f',\n",
       " 'steel best industrial wire products manufacturing company india',\n",
       " 'paramedics emts tattoos piercings',\n",
       " 'kind programming language learn want debug game making website like zondle com',\n",
       " 'thriller lawsuit detective tv series would recommend see',\n",
       " 'reactants photosynthesis',\n",
       " 'person extremely low tolerance weed get second hand high vapor',\n",
       " 'boyfriend ignoring fight',\n",
       " 'mind blowing technologies tools exist people know',\n",
       " 'best exercises get six pack',\n",
       " 'foxmowingnsw take care overgrown lawns long grass',\n",
       " 'good tablet',\n",
       " 'famous women formal wear clothing brands india',\n",
       " 'would good switch accenture yodlee manhattan associates india java professional years experience',\n",
       " 'occupy wall street',\n",
       " 'common loyalty reciprocity silicon valley',\n",
       " 'speed continuous discrete',\n",
       " 'times banks usually open',\n",
       " 'configure beetel tc wifi modem work airtel connection',\n",
       " 'areas research tend go underfunded',\n",
       " 'terrifying commando operation inside india',\n",
       " 'dark matter waves double slit experiment',\n",
       " 'best places visit pattaya',\n",
       " 'pretty women liked look noticed everyone',\n",
       " 'major effects cambodia earthquake effects compare sanriku earthquake',\n",
       " 'file complaint telecom service centre',\n",
       " 'best architecture college nagpur',\n",
       " 'get rid visible pores nose',\n",
       " 'long take solve piece puzzle',\n",
       " 'computer networks calculate rtt round trip time simply propagation delay transmission time another propagation delay',\n",
       " 'war coming',\n",
       " 'think fixiegear com',\n",
       " 'chances mba score class class graduation',\n",
       " 'hotel lachen hill station would safe unmarried couples without harassment police hotel staff moral police',\n",
       " 'lose weight dont eat',\n",
       " 'things want accomplish die',\n",
       " 'probability getting exactly heads toss coins',\n",
       " 'get hdfs bytes read write spark applications',\n",
       " 'think cutoff kvpy sa would',\n",
       " 'work tcs green belt certified career mnc',\n",
       " 'forgotten number combination american tourister bag reset',\n",
       " 'improve story writing skills',\n",
       " 'enhance english language',\n",
       " 'scope supply chain management usa',\n",
       " 'maternal cousin maternal cousin cousin',\n",
       " 'best way clean tile shower',\n",
       " 'true modi government done corruption rafale deal overpricing jets upa',\n",
       " 'essential difference wholesale price index wpi consumer price index cpi two relevant pertaining india',\n",
       " 'correct trouble worth trouble worth',\n",
       " 'prepare death',\n",
       " 'instagram let log',\n",
       " 'self publish book kuwait',\n",
       " 'main reason breakup',\n",
       " 'interesting experiences incidents took place practice school',\n",
       " 'feel like content goes viral',\n",
       " 'make easy money online',\n",
       " 'taste sense determines preference chocolate vanilla strawberry like three',\n",
       " 'best kitty photo ever snapped',\n",
       " 'someone tell saved chat snapchat',\n",
       " 'improve logical programming skills',\n",
       " 'beautiful tourist destination chhattisgarh',\n",
       " 'difference application programming systems programming',\n",
       " 'worth ece graduate work firm',\n",
       " 'muhammad pedophile',\n",
       " 'arun jaitley cunning dishonest politician india',\n",
       " 'build logic development programming languages',\n",
       " 'red eyes darkness metal dragon',\n",
       " 'discrimination exist',\n",
       " 'lose weight days',\n",
       " 'tips get snorlax pokemon go',\n",
       " 'jurassic park jeff goldblum performance considered good',\n",
       " 'global warming real cold last winter',\n",
       " 'get insurance iphone india',\n",
       " 'american people elect donald trump president',\n",
       " 'code block caller id',\n",
       " 'bigger animals live longer',\n",
       " 'purpose desexing cat serves',\n",
       " 'procedure space shuttle transatlantic abort',\n",
       " 'many cups water standard water bottle',\n",
       " 'would israel exist today holocaust happened',\n",
       " 'view move scrap rupee notes effects',\n",
       " 'full form hdfc bank icici bank',\n",
       " 'pheromones work',\n",
       " 'determine electronic charges',\n",
       " 'dont homosexuals undergo gender transition transexuals homosexuals',\n",
       " 'abolishing rs rs notes reduce corruption identifying black money',\n",
       " 'someone help hack gmail account',\n",
       " 'years old girl height increase height',\n",
       " 'best way become freelancer',\n",
       " 'see viewed instagram',\n",
       " 'media talking hillary clinton health clearly serious health issues apparently issue avoided',\n",
       " 'best ways prepare contestant jeopardy',\n",
       " 'systems biology used understand dopamine',\n",
       " 'deal short tempered father',\n",
       " 'string quartet titanic really keep playing sunk',\n",
       " 'many times girls boys masturbate week',\n",
       " 'honey go bad',\n",
       " 'physics someone help solve',\n",
       " 'lose weight',\n",
       " 'framer js viable option web desktop interaction design prototyping intended mobile',\n",
       " 'best chess app help learn',\n",
       " 'get list gmail accounts',\n",
       " 'hard puberty hit',\n",
       " 'two moving observers cycling around equator opposite direction c measure exchanging light signals orbit',\n",
       " 'best way learn c language',\n",
       " 'difficult easy complete ucsd masters cs quarters',\n",
       " 'best color car',\n",
       " 'correct father name th marksheet years passing',\n",
       " 'language learn beside english',\n",
       " 'straight student motivation whatsoever go school someone help fight',\n",
       " 'find people instagram name',\n",
       " 'stop getting irritated easily',\n",
       " 'dark web happens',\n",
       " 'hamlet considered tragic hero',\n",
       " 'could consequences recalling rupee note',\n",
       " 'causes new cricket ball swing air',\n",
       " 'isro get job',\n",
       " 'soccer players get paid much',\n",
       " 'aircraft stop using variable sweep wings like f',\n",
       " 'one become reseller mac makeup products',\n",
       " 'actors really kiss',\n",
       " 'student healer',\n",
       " 'fertilization occur humans',\n",
       " 'lesser known things nsit',\n",
       " 'nutritional value potato chips',\n",
       " 'logically possible buddha discover self exist',\n",
       " 'want join theatre group delhi groups procedure join',\n",
       " 'lose weight face',\n",
       " 'salary ias officer trainee th cpc',\n",
       " 'rumor marilyn manson ribs removed',\n",
       " 'develop healthy self esteem confidence',\n",
       " 'download videos google drive camera roll',\n",
       " 'trump win',\n",
       " 'makes mercedes benz g class expensive spite ugly looks',\n",
       " 'best universities ms computer engineering us',\n",
       " 'notable small groups people changed world',\n",
       " 'major social faux pas avoid visiting mauritius',\n",
       " 'easy ways install libraries want install numpy panda scikit learn num word using python command line pycharm',\n",
       " 'love fart',\n",
       " 'gun purpose',\n",
       " 'practice president prime minister supreme power indian democracy',\n",
       " 'multiply two numbers',\n",
       " 'pizza originate',\n",
       " 'tractors big rear wheels small front wheels',\n",
       " 'hindu religion growing',\n",
       " 'normal dirty thoughts crush',\n",
       " 'many students take cl mock',\n",
       " 'spavista could spavista improved',\n",
       " 'become famous talent',\n",
       " 'good list animals ordered intelligence',\n",
       " 'saddest thing never shared',\n",
       " 'tennessee major natural resources preserved',\n",
       " 'time travel possible yes travel past future',\n",
       " 'one hate shahrukh khan',\n",
       " 'nostalgia painful',\n",
       " 'internet connection type',\n",
       " '',\n",
       " 'columns called periodic table',\n",
       " 'genuine ways earn money online',\n",
       " 'cibil work',\n",
       " 'caused big bang one bang',\n",
       " 'europa report fail make presence felt box office',\n",
       " 'things one besides job live decent life',\n",
       " 'potty train english bulldog pitbull mix puppy',\n",
       " 'special cares weeks old pit bull puppies',\n",
       " 'know difficult find use search engine',\n",
       " 'noticed students troubling adult elderly citizens bus done stop disturbing passengers',\n",
       " 'countries invaded occupied philippine committed atrocities philippines people past years history',\n",
       " 'bought new lenovo plus hide file one sees',\n",
       " 'real world problems fixed us',\n",
       " 'know pinched nerve tailbone',\n",
       " 'look company investing',\n",
       " 'going flying cars',\n",
       " 'happen pakistan declared terrorist state',\n",
       " 'long usps first class international take ship packages hong kong',\n",
       " 'ensure help gain weight',\n",
       " 'often hear someone say fine others say fine meanings',\n",
       " 'need antenna converter box',\n",
       " 'question asked fresher party',\n",
       " 'happens antimatter matter collide',\n",
       " 'word miserable person purposely makes others miserable',\n",
       " 'share gif images whatsapp without converting gif video',\n",
       " 'feel like penis inside vagina',\n",
       " 'make great book trailer',\n",
       " 'people say make party party spanish',\n",
       " 'good things azerbaijan',\n",
       " 'normal indian culture man walk front woman instead walking beside',\n",
       " 'start cyber security company',\n",
       " 'icf prinicple complaince offices',\n",
       " 'uno',\n",
       " 'press handstand',\n",
       " 'term secular religion semantically correct',\n",
       " 'estimated middle class population asia africa latin america',\n",
       " 'access reddit indonesia since site banned indonesian government',\n",
       " 'difference company one founder one co founder company two co founders',\n",
       " 'girl female bodies turn make bi',\n",
       " 'india respond uri attacks',\n",
       " 'course big data hadoop msde gov pmkvy',\n",
       " 'yawn lot night could reason',\n",
       " 'rhetorical question',\n",
       " 'iconic photos',\n",
       " 'read ibook file android mobile',\n",
       " 'quora little politically correct',\n",
       " 'things new employees know going first day delek',\n",
       " 'meaning life one sentence',\n",
       " 'iq overrated',\n",
       " 'feel shy talk girls',\n",
       " 'best restaurants try visiting st catharines try',\n",
       " 'nurse even medical conditions require regular check ups clinic',\n",
       " 'best cab service mumbai',\n",
       " 'embarrassing moment ever',\n",
       " 'chinese people hate japan',\n",
       " 'worst books often required reading german middle high school students',\n",
       " 'bernie sanders become democratic nominee hillary resign due health problems',\n",
       " 'want remembered die',\n",
       " 'meaning living life',\n",
       " '',\n",
       " 'escalators necessary public places',\n",
       " 'india still developing country',\n",
       " 'u atrocity korean vietnam wars well known leaders prosecuted war crimes',\n",
       " 'make husband love ever',\n",
       " 'government mandates require fortune companies use minority owned vendors',\n",
       " 'al exist diatomic molecule molecule al',\n",
       " 'outgoing',\n",
       " 'moto g moto g rd gen get android nougat update',\n",
       " 'varicocele erectile dysfunction treated',\n",
       " 'lose weight',\n",
       " 'price huawei honor holly falling',\n",
       " 'many countries access apple app store',\n",
       " 'human penis look like',\n",
       " 'greatest king time',\n",
       " 'start business without investing money',\n",
       " 'could possible reasons nitish kumar backing pm narendra modi demonetization',\n",
       " 'india cpec',\n",
       " 'advantages c language',\n",
       " 'left handed people intelligent right handed people',\n",
       " 'employees matthews international good work life balance differ across positions departments',\n",
       " 'best way make money',\n",
       " 'first beginner ways start competitive programming',\n",
       " 'best book philosophy beginners',\n",
       " 'ordered something flipkart first time chose pay cash delivery know home pay',\n",
       " 'get best cleaning maintenance service sydney',\n",
       " 'form substance linguistics',\n",
       " 'inappropriate wear singlet says daddy front around dad',\n",
       " 'enable voice coming redmi note without earphones calling though volume already low',\n",
       " 'chances donald trump could humiliated loss election would end committed commit suicide',\n",
       " 'cricket overrated game india',\n",
       " 'get solutions rc mukherjee',\n",
       " 'beat ac company india',\n",
       " 'would win fight goku superman',\n",
       " 'advantages lots friends',\n",
       " 'reverse phone lookup service really free',\n",
       " 'points people drink coffee',\n",
       " 'would photonic wifi look like',\n",
       " 'happens two laser beams hit precisely degrees phase',\n",
       " 'medieval portuguese discover americas',\n",
       " 'unusual different food cuisine canada',\n",
       " 'safest time sex without condom',\n",
       " 'course take',\n",
       " 'phd program would recommend someone interested studying environmental political theory climate change indigenous politics',\n",
       " 'performing rituals named munja brahmin community brahmins cut wheat doughed cow',\n",
       " 'homeopathy cures scalp psoriasis',\n",
       " 'best way lose weight gain back',\n",
       " 'best tools seo analysis',\n",
       " 'arnab goswami think',\n",
       " 'words rhyme',\n",
       " 'ever date someone really liked said something completely turn forever',\n",
       " 'best free ringtones iphone',\n",
       " 'pros cons skype',\n",
       " 'maximum stress theory cylinder yield strength used maximum allowed stress',\n",
       " 'would isps block facebook without net neutrality',\n",
       " 'us one million dollar bill',\n",
       " 'buy nexus p oneplus',\n",
       " 'phrases mandarin useful real conversations show dictionary phrasebook',\n",
       " 'defeat purpose demonetizing rupee bill government india introduces new rupee bills',\n",
       " 'meaning surgical strike',\n",
       " 'people ask questions quora easily answered google',\n",
       " 'regular use livon hair serum lead hairfall',\n",
       " 'best chief minister india',\n",
       " 'find average acceleration',\n",
       " 'dc v enough power hardisk connecting phone',\n",
       " 'join indian merchant navy b tech',\n",
       " 'good introduction',\n",
       " 'dc universe metropolis new york city gotham city located',\n",
       " 'feel good orgasm',\n",
       " 'cached data cause problems clear cached data',\n",
       " 'lawyer day like life lawyer',\n",
       " 'decision indian government demonetize notes right wrong',\n",
       " 'indian hindu want marry malay muslim girl make possible one hepl',\n",
       " 'many types hard disk',\n",
       " 'panties worn pantyhose',\n",
       " 'whats best thing quora',\n",
       " 'actual reasons people think donald trump would bad president including appearance wealth',\n",
       " 'study guides use pass z exam',\n",
       " 'son year old agoraphobic refuses treatment work heart kick',\n",
       " 'characteristics pluralistic society',\n",
       " 'difference kruskal prim algorithm',\n",
       " 'get girlfriend easily',\n",
       " 'overclock cpu',\n",
       " 'pay ikea bed delivery get taxi take home',\n",
       " 'suitable inpatient drug alcohol rehab center near jenkins county ga',\n",
       " 'buy used new car fresher industry pays k per month',\n",
       " 'trace cyber criminal',\n",
       " 'score rank ca ipcc may',\n",
       " 'track someone using phone number',\n",
       " 'best buy mi redmi note',\n",
       " 'many gay couples muscular buff evolutionary',\n",
       " 'wasps good things',\n",
       " 'best books read learn human psychology',\n",
       " 'would make day',\n",
       " 'increase concentration',\n",
       " 'universe expanding without limit dark vacuum energy created expands',\n",
       " 'crushonoffers com',\n",
       " 'call person without personality',\n",
       " 'difference c c',\n",
       " 'programming language beginner learn first',\n",
       " 'would pug lick feet lick air finally settles',\n",
       " 'current affairs group discussion topics',\n",
       " 'mean dc motor full load half load',\n",
       " 'muslim world secular',\n",
       " 'phonegap still uses web sql even deprecated',\n",
       " 'l improve communication skills',\n",
       " 'feel secured someone',\n",
       " 'best gift ever recieved',\n",
       " 'person increase tolerance pain',\n",
       " 'existence credit scores influence good repayment behavior',\n",
       " 'staphylococcus aureus resistant antibiotics',\n",
       " 'value math pi math calculated',\n",
       " 'charles j hamm leadership program phillips exeter stimulating taught via harkness method',\n",
       " 'heard quora filled many left wing liberals true',\n",
       " 'get high subutex',\n",
       " 'tell best guy friend likes',\n",
       " 'key points look companies investing',\n",
       " 'meaning forward integration',\n",
       " 'wash clothes without detergent',\n",
       " 'singapore exchange rate',\n",
       " 'best way lose weight gain back',\n",
       " 'best way maintain relationship',\n",
       " 'looking bluetooth wi fi back hub ble devices android windows ui suggestions',\n",
       " 'muhammad teach spitting left side stops bad dreams',\n",
       " 'would one know whether addicted vicodin',\n",
       " 'best places visit goa days',\n",
       " 'indonesia muslim bali hindu',\n",
       " 'vishwas nangare patil',\n",
       " 'empty space consist stuff displaced matter',\n",
       " 'much money ne yo earn week',\n",
       " 'shoud go cambridge imperial engineering',\n",
       " 'improve writing skill blogging',\n",
       " 'many times week married couples sex',\n",
       " 'star wars expanded universe',\n",
       " 'ways suggest curb air pollution delhi implemented also',\n",
       " 'worst ragging experiences college days',\n",
       " 'language beautiful world',\n",
       " 'improve programming style skills c language',\n",
       " 'mean ghost writer',\n",
       " 'tell full lyric tenors spinto tenors dramatic tenors heldentenors baritenors considered low tenors',\n",
       " 'healthy eat chapati every day',\n",
       " 'less known tourist destinations india',\n",
       " 'suitable solar panel installation provider near alameda california ca',\n",
       " 'chandragupta institute management patna',\n",
       " 'birds learn fly',\n",
       " 'get professional reliable envelope printing service sydney',\n",
       " 'meaning happiness',\n",
       " 'epic picture ever taken',\n",
       " 'masturbation affect growth',\n",
       " 'ideas come easily taking shower',\n",
       " 'yr old boy marry girl yr old',\n",
       " 'get best online tutorials educational videos youtube videos opencourseware mooc related biomedical engineering courses',\n",
       " 'meaning expression smoke mirrors',\n",
       " 'total investment polyhouse farming profit',\n",
       " 'looking switch android ios give reasons suggestions insight n always used android',\n",
       " 'stomach growling hungry',\n",
       " 'visionary gleam fled elaborate stages human life reference william wordsworth ode intimations immortality',\n",
       " 'andrew ng opinion numenta',\n",
       " 'people let atheism define lives',\n",
       " 'get cheap branded clothes delhi boys',\n",
       " 'way make money online',\n",
       " 'smallest molecule biggest molecule',\n",
       " 'know addicted quora',\n",
       " 'make money playing poker',\n",
       " 'get cold sweaty hands',\n",
       " 'would win fight goku hulk',\n",
       " 'much miner gold rush alaska make per season much would per episode',\n",
       " 'quora hate donald j trump',\n",
       " 'ask first question quora',\n",
       " 'sme',\n",
       " 'men supposed accept pay equality women princeton prostituting',\n",
       " 'scored percentile cat iims expect call wat gd pi rounds',\n",
       " 'prove',\n",
       " 'offline videos youtube get saved',\n",
       " 'always introverted',\n",
       " 'editing photo like',\n",
       " 'meant jailbreaking iphone',\n",
       " 'best ias institute india',\n",
       " 'badass like harvey specter',\n",
       " 'possible become md adult e starting medical school late',\n",
       " 'die',\n",
       " 'know blocked android phone',\n",
       " 'minimum time required build pounds quality muscle average adult',\n",
       " 'shamanism religion',\n",
       " 'bad woman biologically masturbate',\n",
       " 'feel nitian boyfriend',\n",
       " 'kind indian girl cheat husband able satisfy bed',\n",
       " 'analyze short story',\n",
       " 'try pretty',\n",
       " 'get esta travel us validity j visa',\n",
       " 'underrated actor actress bollywood',\n",
       " 'porcelain mean',\n",
       " 'convenient flights leeds ibiza ibiza tourist attractions compare ones madrid',\n",
       " 'way delete photo albums iphone',\n",
       " 'many people still dislike even hate britain',\n",
       " 'best book learn selenium',\n",
       " 'courses take get masters computer science',\n",
       " 'political party win punjab assembly elections',\n",
       " 'live die',\n",
       " 'subscribers youtube',\n",
       " 'phrase help god removed congressional committees swearing witnesses testimony',\n",
       " 'macbook retina screens fragile',\n",
       " 'solution',\n",
       " 'nyc fire department called fdny nyfd like police department nypd',\n",
       " 'psychiatric evaluation questions generated',\n",
       " 'steak gluten free',\n",
       " 'make week much taxes',\n",
       " 'life suck bad',\n",
       " 'laptop buy mac os windows os',\n",
       " 'balarka technologies pvt limited delhi',\n",
       " 'recently completed engineering electronics communication make carrier telecom sector',\n",
       " 'iphone upgrade iphone',\n",
       " 'indian secular support kashmir referendum support hindu rashtra',\n",
       " 'differences chinese western cultures',\n",
       " 'green card holder naturalized without taking american passport country india allow dual citizenship',\n",
       " 'like customer service representative google',\n",
       " 'good intel celeron gaming',\n",
       " 'mba mtech',\n",
       " 'pair fitrist band phone',\n",
       " 'check voicemail online',\n",
       " 'important programming languages learn nowadays',\n",
       " 'love girl boyfriend',\n",
       " 'density equilibrium mixture',\n",
       " 'watch cw live',\n",
       " 'difference static dynamic system',\n",
       " 'people deal boredom',\n",
       " 'many keywords eiffel programming language latest version',\n",
       " 'like switch macbook windows user years',\n",
       " 'first sex experience',\n",
       " 'environmental issue',\n",
       " 'brands tom ford wear',\n",
       " 'theories mystery bermuda triangle',\n",
       " 'everything',\n",
       " 'best way prepare elitmus exam',\n",
       " 'color mixing green blue make',\n",
       " 'feel numb important situations unable think smartly improve presence mind',\n",
       " 'key elements game',\n",
       " 'important thing life',\n",
       " 'top podcasts developers listen',\n",
       " 'many plastic surgeries michael jackson',\n",
       " 'reddit website mean deleted appears commenter name go',\n",
       " 'eligibility criteria ssc',\n",
       " 'scope course',\n",
       " 'eliot mean said april cruelest month',\n",
       " 'view arvind kejriwal recent statement concerning indian surgical strike pakistan',\n",
       " 'vietnam better india',\n",
       " 'best places hangout weekend pune',\n",
       " 'new stocks come purchased sold stocks buying power earned selling stocks',\n",
       " 'preparing upsc plan strategy gs mains',\n",
       " 'another word',\n",
       " 'publish theses burns international library thesis',\n",
       " 'best possible way play clash clans asus eee pc cx native android x downloaded open project installed',\n",
       " 'history apple inc iphone advertisements time always set clock',\n",
       " 'career options international relationships major',\n",
       " 'israel give territory arab countries attacked',\n",
       " 'university kaiserslautern like ms cs',\n",
       " 'embarrassing thing happened front friend',\n",
       " 'best compiler python',\n",
       " 'increase traffic website',\n",
       " 'necessary connect choke series tube light',\n",
       " 'donald trump win elections',\n",
       " 'father earth',\n",
       " 'girl get pregnent without breaking hymen',\n",
       " 'one think compulsory knowledge experience technology',\n",
       " 'prolific physicists alive',\n",
       " 'universities maxim integrated recruit new grads majors looking',\n",
       " 'difference feudalism fascism',\n",
       " 'mba help long term product management career help',\n",
       " 'regular simple habits lead achievement far',\n",
       " 'comiited mistake dump girl good listner less demanding grounded getting suffocated relationship',\n",
       " 'long take double strand break brain cell repair',\n",
       " 'join terrorist group',\n",
       " 'agreements made normal papers stamp paper valid parties involved agreement duly signed used evidence proof court house',\n",
       " 'gentleman c',\n",
       " 'would happen people disappeared earth',\n",
       " 'opinion attractive man game thrones',\n",
       " 'much average cost replace alternator',\n",
       " 'severe itching due sunburn',\n",
       " 'organisms life begin',\n",
       " 'phone buy rs',\n",
       " 'best pc game played',\n",
       " 'one start programming c',\n",
       " 'hillary clintons plan budget nasa',\n",
       " 'happen eat less calories day',\n",
       " 'best cities visit europe',\n",
       " 'open account buy indonesian stocks indonesia',\n",
       " 'marks class sa english maths ss science hindi fas get cgpa class',\n",
       " 'consolidated financial statements limitations',\n",
       " 'improve professional resume',\n",
       " 'safety precautions handling shotguns proposed nra minnesota',\n",
       " 'calling people white trash action racial discrimination',\n",
       " 'common prostitution saudi arabia',\n",
       " 'world highest battlefield altitude',\n",
       " 'get girl',\n",
       " 'percentage mobile app downloads convert installs india',\n",
       " 'dinosaurs reptiles come birds closest relatives instead existing reptiles',\n",
       " 'suggest good name related means sun star',\n",
       " 'transformers characterized power factor',\n",
       " 'people getting paid like things posts pages etc facebook',\n",
       " 'slope force vs acceleration graph represent',\n",
       " 'come car filling cng',\n",
       " 'formula barium nitrogen calculated',\n",
       " 'lenovo k plus support volte',\n",
       " 'arm sting go numb shooting meth',\n",
       " 'biggest regret life',\n",
       " 'buy iphone wait buy iphone',\n",
       " 'state pay welfare rather requiring ex husbands pay alimony take care needs divorced former housewives',\n",
       " 'julian assange dead alive',\n",
       " 'lipton green tea related weight loss',\n",
       " 'study medicine effectively',\n",
       " 'pick best pornographic movie golden age porn',\n",
       " 'electromagnetic spectrum',\n",
       " 'meant natural frequency',\n",
       " 'difference standard deviation mean deviation application',\n",
       " 'called jews allowed exist',\n",
       " 'lying also lie',\n",
       " 'uc look improvement',\n",
       " 'eat meat dairy products',\n",
       " 'much penny worth',\n",
       " 'get internship google india',\n",
       " 'good books read time management',\n",
       " 'effect valley storage',\n",
       " 'popular sport players fielded one time',\n",
       " 'time travel possible',\n",
       " 'headlight good replacement suzuki gixxer headlamp',\n",
       " 'laptop buy upto rs',\n",
       " 'export twitter lists text file',\n",
       " 'forgot facebook password email password log facebook',\n",
       " 'guaranteed honest response one question would question would ask',\n",
       " 'many strongly independent men take relationships lightly enter',\n",
       " 'people overweight obese show indications',\n",
       " 'get girlfriend lose weight',\n",
       " 'factual basis evidence psychic abilities',\n",
       " 'japanese sushi chefs say enter',\n",
       " 'get thin thighs',\n",
       " 'final year appearing candidate apply indian coast guard ac entry',\n",
       " 'equity fair cto role startup rev funding users poorly designed prototype redesign develop',\n",
       " 'get investors online magazin',\n",
       " 'legit ways earn money online',\n",
       " 'best video game made game maker high revenues',\n",
       " 'blind people dreams',\n",
       " 'saltwater taffy candy imported germany',\n",
       " 'someone make movie life would hope would play',\n",
       " 'want buy plot make house need organization offers loan facility home keep unwell contact',\n",
       " 'men likely assholes compared women',\n",
       " 'concentrate better way studies',\n",
       " 'women like men butts shape man butt matter sexual pleasure',\n",
       " 'think first presidential debate hillary clinton donald trump',\n",
       " 'x gen night vision monocular focus distance meters kind ir flashlight use see farthest',\n",
       " 'importance dreaming aboriginal culture',\n",
       " 'eye power fit criteria vision exactly eye vision fit',\n",
       " 'hosni mubarak',\n",
       " 'get nda',\n",
       " 'philosophical science fiction fantasy books read',\n",
       " 'indonesia vietnam north korea love communism',\n",
       " 'energy transferred earth surface atmosphere',\n",
       " 'quora make clear sign process youre required real full name',\n",
       " 'many views answers required become top writer quora',\n",
       " 'worst experiences indian railways',\n",
       " 'stock market',\n",
       " 'year old make money without getting job',\n",
       " 'euclid algorithm',\n",
       " 'ask prostitute make porn video sex legal valid loophole',\n",
       " 'deepest lake europe lake flora fauna compare lake van',\n",
       " 'pros cons legalising prostitution india',\n",
       " 'confess girl',\n",
       " 'relationship north korea japan',\n",
       " 'present scale officer salary public sector banks',\n",
       " 'kind long term impact bernie sanders campaign',\n",
       " 'parents wash hands',\n",
       " 'superstition behind twitching right eye',\n",
       " 'succeed chasing shy guy',\n",
       " 'primary secondary businesses',\n",
       " 'dogs chocolate',\n",
       " 'come apple promote ces',\n",
       " 'difference moss algae',\n",
       " 'illegal surf browse deep web',\n",
       " 'current technology testing',\n",
       " 'best single player fps opinion',\n",
       " 'load chat w solar panel',\n",
       " 'confirm president extra terrestrial life discovered',\n",
       " 'great classical philosophers led debauched lifestyle compared rhetoric',\n",
       " 'tallest',\n",
       " 'since credit card gives cash back need report irs',\n",
       " 'saina nehwal changed coach gopichand vimal kumar',\n",
       " 'reason man feels awkward certain woman',\n",
       " 'met five members family',\n",
       " 'difference c embedded c',\n",
       " 'better terms future growth average placement ccap crisil mba finance top colleges india',\n",
       " 'climate california coastal regions compare climate georgia',\n",
       " 'avoid sleeping class',\n",
       " 'best laptop k approx',\n",
       " 'procedure filing fir',\n",
       " 'updating package linux old package deleted',\n",
       " 'design patterns spring framework used',\n",
       " 'indian footballer ever get chance play teams like barcelona real madrid manchester united chelsea',\n",
       " 'buddha say god',\n",
       " 'way view spotify play history',\n",
       " 'lose weight really quick',\n",
       " 'quora biased towards trump',\n",
       " 'personal attributes importance',\n",
       " 'classical imagery used spencer epithalomian prothalomian',\n",
       " 'big labrador retriever chihuahua mix get',\n",
       " 'issue new provinces pakistan',\n",
       " 'tubes come back normal tubal ligation',\n",
       " 'best intuit quickbooks support plans',\n",
       " 'see views instagram video',\n",
       " 'procees getting new registration certificate two wheeler lost jaipur rajasthan',\n",
       " 'advantages using bronze utensils eating',\n",
       " 'cap',\n",
       " 'mit advertise master program sloan school management heavily',\n",
       " 'dont know talk people',\n",
       " 'make money uploading videos youtube',\n",
       " 'killed che guevara',\n",
       " 'exactly banning rs rs notes curb problem black money',\n",
       " 'ask girl hang',\n",
       " 'provide sex alone female rajasthan',\n",
       " 'good macbook pro gaming',\n",
       " 'problem would using sanskrit programming',\n",
       " 'best laptop rs',\n",
       " 'greatest compliment someone ever given',\n",
       " 'rich',\n",
       " 'theories mystery bermuda triangle',\n",
       " 'lose weight drinking ice cold water',\n",
       " 'perfect numbers',\n",
       " 'many devices one netflix account simultaneously stream',\n",
       " 'feel sleepy studying',\n",
       " 'build muscle calisthenics',\n",
       " 'prestigious medical specialty',\n",
       " 'l wan na know advices translation career suggestions companies centers courses',\n",
       " 'way prevent hair loss',\n",
       " 'career seen many young talents come go look understand guy would go way',\n",
       " 'whales sense smell',\n",
       " 'navy sailors jags stationed places like afghanistan iraq',\n",
       " 'celebrities like',\n",
       " 'iphone slow refresh',\n",
       " 'better kiss kissed',\n",
       " 'motivate continue life adversity',\n",
       " 'smuggle dog shelter virginia',\n",
       " 'since exterior wounds heal time human body heal interior wound time well',\n",
       " 'difference meaning two sentences minute upon waking barely feel feet upon minute waking barely feel feet',\n",
       " 'done admin certification salesforce su',\n",
       " 'revolutionary discoveries made th th centuries',\n",
       " 'hexagon saturn also spinning',\n",
       " 'best way clean flat screen monitor',\n",
       " 'get rid acne scars chest',\n",
       " 'biggest problems india',\n",
       " 'views freedom',\n",
       " 'best category top hotels rajasthan',\n",
       " 'relation china russia',\n",
       " 'cold fusion pseudoscience',\n",
       " 'find list gmail addresses',\n",
       " 'basic difference love infatuation',\n",
       " 'improve chances getting ivy league school',\n",
       " 'ok bath medicine',\n",
       " 'took trips thats km thats km draw show ur resultant displacement trips could km e km n km help anyone',\n",
       " 'combination diet exercise tips result losing belly fat building six pack abs',\n",
       " 'happens stock options decide leave company',\n",
       " 'much time required learn c',\n",
       " 'one meet british irish people toronto gta area',\n",
       " 'ways attain air jee advance',\n",
       " 'interesting story people life',\n",
       " 'atom solid liquid gas none',\n",
       " 'connect wifi without password',\n",
       " 'illegal discriminate renting property reason listed',\n",
       " 'recover gmail password recovery mobile number gmail address',\n",
       " 'improve math skills',\n",
       " 'time never go back',\n",
       " 'possible increase coins dream league soccer',\n",
       " 'cultural myths examples',\n",
       " 'fix ssl connection error google chrome',\n",
       " 'old',\n",
       " 'even slight difference ground clearance car inch alloys inch alloys',\n",
       " 'know whether person lying',\n",
       " 'make new friends',\n",
       " 'know guy cheating',\n",
       " 'schema sociological imagination',\n",
       " 'sex boy without condom without risk pregnancy',\n",
       " 'stop using subtitles watching english movies tv series ok',\n",
       " 'made huge mistake telling',\n",
       " 'main cause modern day terrorism',\n",
       " 'income tax india missed taking copy form previous employer possible recover tax website',\n",
       " 'installed kik lost dearest friend account way get account back',\n",
       " 'proof alien life form',\n",
       " 'best book learning python absolute beginners',\n",
       " 'possible time travel past',\n",
       " 'happens ignore jury duty summons california',\n",
       " 'select topics quora',\n",
       " 'cobras spit venom',\n",
       " 'get cse lnmiit maybe ece mechatronics thapar university one choose',\n",
       " 'donald trump qualified president',\n",
       " 'best advice someone insecure',\n",
       " 'level english intermediate advanced level',\n",
       " 'eat gain weight',\n",
       " 'start career political journalism',\n",
       " 'better satin silk',\n",
       " 'believe humans inherently good inherently evil',\n",
       " 'conditions cause refrain filling online registration forms sites',\n",
       " 'frcp medical degree',\n",
       " 'shiuld become astronaut',\n",
       " 'snapchat initially fund',\n",
       " 'little lock icon next battery life iphone',\n",
       " 'indian army killing innocent civilians indian controlled kashmir',\n",
       " 'get followers twitter instagram',\n",
       " 'use iphone metro pcs',\n",
       " 'snapchat calculate best friends',\n",
       " 'general view iran ancient persia ancient countries like greece italy empire enemies ancient persians',\n",
       " 'best websites learn programming concepts',\n",
       " 'drawings step step pictures',\n",
       " 'significance battle somme battle compare contrast battle kiev',\n",
       " 'list hour polls close state order election',\n",
       " 'would earth eventually become venus like global warming went unaddressed',\n",
       " 'transfer offline youtube video sd card android',\n",
       " 'think wealthy affiliate',\n",
       " 'people dream colour others',\n",
       " 'comedians specials get paid netflix backend get viewership information plan tours etc',\n",
       " 'relation mechanical engineering engineering management',\n",
       " 'chemical formula wood',\n",
       " 'sanity testing regression testing',\n",
       " 'quora allow upvotes questions',\n",
       " 'percentage women masturbate average often',\n",
       " 'hillary clinton lost law practice license yes',\n",
       " 'play overwatch competitive level laptop',\n",
       " 'military use many acronyms',\n",
       " 'importance information technology',\n",
       " 'top ecommerce companies france',\n",
       " 'stop overthinking things calm',\n",
       " 'true new rs currency notes india nano gps chip',\n",
       " 'best oyo room properties available non married couples delhi ncr',\n",
       " 'upsc verify number attempts already made candidates',\n",
       " 'track cell phone number free',\n",
       " 'much time take update aadhaar details online',\n",
       " 'difference nationality ethnicity race',\n",
       " 'get job microsoft',\n",
       " 'weather like port townsend wa compared seattle',\n",
       " 'popular adderall uc berkeley',\n",
       " 'rockwool biodegradable',\n",
       " 'people talk silent',\n",
       " 'manage send picture text message iphone',\n",
       " 'drive us full uk license',\n",
       " 'favorite song feeling give',\n",
       " 'weed delivery india',\n",
       " 'access yahoo accounts without still old mobile numbers email associated',\n",
       " 'something like grip strength force measured units mass lbs kg',\n",
       " 'laws getting green card due marriage us compare green card laws mexico',\n",
       " 'linear programming',\n",
       " 'hindu baby girl name starting',\n",
       " 'nepalese people friendly',\n",
       " 'live matrix',\n",
       " 'best shirts buy online india',\n",
       " 'special coimbatore',\n",
       " 'makes research paper good enough published',\n",
       " 'polarity molecules mean',\n",
       " 'gold price india around globe decided',\n",
       " 'study computer fundamental software engineering',\n",
       " 'amazing facts antartica',\n",
       " 'corporate culture like marin software culture different companies',\n",
       " 'dynamic fare rules indian railways absurd',\n",
       " 'one thing plan want change life',\n",
       " 'ted cruz endorse donald trump republican national convention',\n",
       " 'best ways get paying change fee changing flight united',\n",
       " 'proof existence extraterrestrials',\n",
       " 'life become difficult men marriage',\n",
       " 'mermaids really exist',\n",
       " 'tinder delete interests',\n",
       " 'painless way suicide',\n",
       " 'movie wolf wall street',\n",
       " 'earn money using youtube',\n",
       " 'think android ios',\n",
       " 'composition acetic acid',\n",
       " 'microsoft innovating apple',\n",
       " 'large scale precision animations importance level ranked least important regarding hardware components',\n",
       " 'whey protein contain steroids',\n",
       " 'lawyer stage fright fear appearing court get',\n",
       " 'tips making job interview process century bank',\n",
       " 'would superpower',\n",
       " 'could holocaust happen',\n",
       " 'best smartphone k',\n",
       " 'scenarios presented steve wilkos show staged',\n",
       " 'base nick wilde robin hood',\n",
       " 'subtraction infinity infinity',\n",
       " 'invest others money stocks',\n",
       " 'worst hotel malaga',\n",
       " 'happens trisodium phosphate calcium hydroxide mixed',\n",
       " 'best ways increase productivity high school student',\n",
       " 'abusive words english hindi spoken date',\n",
       " 'cheats coc unlimited gems really works yes cheat worked',\n",
       " 'good substitute sherry cooking',\n",
       " 'increase height',\n",
       " 'get child elements within div javascript',\n",
       " 'example analogy',\n",
       " 'human interaction possible absolute silence',\n",
       " 'indore fashionable women',\n",
       " 'antidepressants work everyone',\n",
       " 'facts black knight satellite',\n",
       " 'valence electrons found',\n",
       " 'since hold conversation women get hot body compensate poor social skills',\n",
       " 'one control reactions surprising shocking situations professional requirement',\n",
       " 'think hillary clinton corrupted',\n",
       " 'appeared neet called made two attempts',\n",
       " 'benefits issuing rs note india',\n",
       " 'many traditional kings nepal',\n",
       " 'mission statement tech mahindra',\n",
       " 'healthy chocolate',\n",
       " 'western media anti muslim',\n",
       " 'difference maryapoda archinida',\n",
       " 'completed bsc biotechnology study public health master',\n",
       " 'think rbi new move banning notes',\n",
       " 'reaction sodium phosphate sodium hydroxide',\n",
       " 'unusual aspects politics government greece',\n",
       " 'object moves constant velocity resultant force acting body zero object move forces acting equal zero',\n",
       " 'best vpn service',\n",
       " 'mental process reading quora different reading book',\n",
       " 'beans considered fruit vegetable',\n",
       " 'cc bcc gmail use',\n",
       " 'power need legitimation',\n",
       " 'think move banning rupee notes india nov',\n",
       " 'best thing ever done others',\n",
       " 'difference model scaffold generators',\n",
       " 'hp stream',\n",
       " 'examples right gun militia',\n",
       " 'lcm xy yz zx xy yz zx x',\n",
       " 'biggest challenge starting new business',\n",
       " 'buy spices bulk india',\n",
       " 'barcode bank statement',\n",
       " 'number appended user name profile url indicate',\n",
       " 'would demonetizing rupee notes introducing new rupee notes help curb black money corruption',\n",
       " 'phone unable connect wi fi',\n",
       " 'kfc makes veggie strips fine crispy layer',\n",
       " 'difference price various tours travels website destination flight class date time',\n",
       " 'india need president everything done pm india',\n",
       " 'degrees business field one need order ceo apple',\n",
       " 'tougher cma ca',\n",
       " 'better ronaldo messi',\n",
       " 'hillary clinton feel donald trump',\n",
       " 'venture capitalists angel investors invest projects part time entrepreneurs good business plan idea',\n",
       " 'prayes day muslims',\n",
       " 'energy created conserved expanding universe infinite created yes potential energy potentiality infinite',\n",
       " 'free database application shall use create cmdb asset inventory',\n",
       " 'shift relative beepi',\n",
       " 'vehicle grid buck grid vehicle boost operation wih dc grid side inductors interleaved ckt',\n",
       " 'rudest person ever met',\n",
       " 'new airbus xwb compare boeing dreamliner',\n",
       " 'stop spending time internet',\n",
       " 'know number followers snapchat without adding',\n",
       " 'biggest regret life',\n",
       " 'know love partner',\n",
       " 'difference uber lyft',\n",
       " 'best places visit andaman',\n",
       " 'avoid looking like tourist paris',\n",
       " 'girlfriend broke',\n",
       " ...]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "d6b526a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 17.2 GiB for an array with shape (80856, 28594) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2216/183009235.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[1;33m[\u001b[0m\u001b[0mquestions\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mX_train_q1_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train_q2_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvsplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcount_vect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquestions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#corpus = [train_text_q1, train_text_q2]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36mtoarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1029\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0morder\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1030\u001b[0m             \u001b[0morder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_swap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1031\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_toarray_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1032\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_contiguous\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_contiguous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1033\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Output array must be C or F contiguous'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m_process_toarray_args\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1200\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1201\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1202\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 17.2 GiB for an array with shape (80856, 28594) and data type int64"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "questions = list(X_train_q1) + list(X_train_q2)\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "corpus =  [questions]\n",
    "\n",
    "X_train_q1_arr, X_train_q2_arr = np.vsplit(count_vect.fit_transform(questions).toarray(), 2)\n",
    "\n",
    "#corpus = [train_text_q1, train_text_q2]\n",
    "\n",
    "X_train_counts = count_vect.fit_transform(X_train_q1_arr, X_train_q2_arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "03966f35",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2216/1959865805.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#corpus = [train_text_q1, train_text_q2]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mX_train_counts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcount_vect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq1_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq2_arr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m#pd.DataFrame(X_train_counts.toarray(),columns=count_vect.get_feature_names(),index=['question1','question2'])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1336\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1338\u001b[1;33m         \u001b[0mvocabulary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_count_vocab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfixed_vocabulary_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1339\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1340\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1207\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1208\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1209\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1210\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1211\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_analyze\u001b[1;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpreprocessor\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m             \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_preprocess\u001b[1;34m(doc, accent_function, lower)\u001b[0m\n\u001b[0;32m     67\u001b[0m     \"\"\"\n\u001b[0;32m     68\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlower\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m         \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maccent_function\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccent_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "questions = list(train_limited['question1']) + list(train_limited['question2'])\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "corpus =  [questions]\n",
    "\n",
    "q1_arr, q2_arr = np.vsplit(count_vect.fit_transform(questions).toarray(), 2)\n",
    "\n",
    "#corpus = [train_text_q1, train_text_q2]\n",
    "\n",
    "X_train_counts = count_vect.fit_transform(q1_arr, q2_arr)\n",
    "\n",
    "#pd.DataFrame(X_train_counts.toarray(),columns=count_vect.get_feature_names(),index=['question1','question2'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "feefa437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>best pick line person ever said</td>\n",
       "      <td>epic pick line ever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>meaning cc engine</td>\n",
       "      <td>cc engine indicate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>borivali churchgate kalyan cst journey better</td>\n",
       "      <td>someone think think soulmate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cool psychological hacks</td>\n",
       "      <td>reverse psychology life hacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>create empire st century</td>\n",
       "      <td>ever empire st century</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>post question quora posted many rejected</td>\n",
       "      <td>best ways ask question quora</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>partner get stop cuming quickly</td>\n",
       "      <td>premature ejaculation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>best military instructional videos</td>\n",
       "      <td>right say difference tangential velocity orbit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>wrong stephen colbert right ear</td>\n",
       "      <td>thing inside stephen colbert desk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>prisoners often think jail</td>\n",
       "      <td>often people escape maximum security prisons</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       question1  \\\n",
       "0                best pick line person ever said   \n",
       "1                              meaning cc engine   \n",
       "2  borivali churchgate kalyan cst journey better   \n",
       "3                       cool psychological hacks   \n",
       "4                       create empire st century   \n",
       "5       post question quora posted many rejected   \n",
       "6                partner get stop cuming quickly   \n",
       "7             best military instructional videos   \n",
       "8                wrong stephen colbert right ear   \n",
       "9                     prisoners often think jail   \n",
       "\n",
       "                                           question2  \n",
       "0                                epic pick line ever  \n",
       "1                                 cc engine indicate  \n",
       "2                       someone think think soulmate  \n",
       "3                      reverse psychology life hacks  \n",
       "4                             ever empire st century  \n",
       "5                       best ways ask question quora  \n",
       "6                              premature ejaculation  \n",
       "7  right say difference tangential velocity orbit...  \n",
       "8                  thing inside stephen colbert desk  \n",
       "9       often people escape maximum security prisons  "
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_limited = train_df[:10]\n",
    "train_limited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ec5371",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "trsfm=vectorizer.fit_transform(corpus)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cosine_similarity(trsfm[0:1], trsfm)\n",
    "\n",
    "cosine_similarity(trsfm[0:1], trsfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0269df10",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (Temp/ipykernel_2216/819094467.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\43664\\AppData\\Local\\Temp/ipykernel_2216/819094467.py\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    cosine_similarity(#texto 1 , texto 2)\u001b[0m\n\u001b[1;37m                                         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cosine_similarity(#texto 1 , texto 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53db576",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
